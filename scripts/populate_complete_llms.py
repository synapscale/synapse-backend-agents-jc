#!/usr/bin/env python3
"""
Script para popular TODOS os modelos LLM dispon√≠veis no banco de dados
Vers√£o completa e atualizada com todos os provedores e modelos (Dezembro 2024)
Criado por Jos√© - um desenvolvedor Full Stack
"""

import os
import sys
from pathlib import Path

# Adicionar src ao path
BASE_DIR = Path(__file__).parent.parent
sys.path.append(str(BASE_DIR / "src"))

from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
from synapse.database import get_db
from synapse.models.llm import LLM
from synapse.core.config import settings


def populate_complete_llms():
    """Popula TODOS os LLMs dispon√≠veis no banco de dados"""
    
    # Conectar ao banco
    engine = create_engine(settings.DATABASE_URL)
    SessionLocal = sessionmaker(bind=engine)
    db = SessionLocal()
    
    try:
        print("üöÄ Iniciando popula√ß√£o completa de LLMs...")
        
        # Limpar LLMs existentes se solicitado
        existing_count = db.query(LLM).count()
        if existing_count > 0:
            print(f"‚ö†Ô∏è  Encontrados {existing_count} LLMs existentes.")
            response = input("Deseja substituir todos? (s/N): ").lower()
            if response == 's':
                db.query(LLM).delete()
                db.commit()
                print("üóëÔ∏è  LLMs existentes removidos.")
            else:
                print("‚úÖ Mantendo LLMs existentes. Adicionando apenas novos.")
        
        # TODOS os LLMs dispon√≠veis (Dezembro 2024)
        llms_data = [
            # ========================================
            # OPENAI - Modelos mais recentes
            # ========================================
            {
                "name": "gpt-4o",
                "provider": "openai",
                "model_version": "2024-11-20",
                "cost_per_token_input": 0.0000025,
                "cost_per_token_output": 0.00001,
                "max_tokens_supported": 16384,
                "supports_function_calling": True,
                "supports_vision": True,
                "supports_streaming": True,
                "context_window": 128000,
                "llm_metadata": {
                    "description": "GPT-4o - Modelo mais avan√ßado da OpenAI com vis√£o",
                    "release_date": "2024-11-20",
                    "capabilities": ["text", "vision", "function_calling", "reasoning"],
                    "best_for": ["An√°lise complexa", "Vis√£o computacional", "Racioc√≠nio avan√ßado"]
                }
            },
            {
                "name": "gpt-4o-mini",
                "provider": "openai",
                "model_version": "2024-07-18",
                "cost_per_token_input": 0.00000015,
                "cost_per_token_output": 0.0000006,
                "max_tokens_supported": 16384,
                "supports_function_calling": True,
                "supports_vision": True,
                "supports_streaming": True,
                "context_window": 128000,
                "llm_metadata": {
                    "description": "GPT-4o Mini - Vers√£o r√°pida e econ√¥mica do GPT-4o",
                    "release_date": "2024-07-18",
                    "capabilities": ["text", "vision", "function_calling"],
                    "best_for": ["Tarefas r√°pidas", "Alto volume", "Custo-benef√≠cio"]
                }
            },
            {
                "name": "gpt-4-turbo",
                "provider": "openai",
                "model_version": "2024-04-09",
                "cost_per_token_input": 0.00001,
                "cost_per_token_output": 0.00003,
                "max_tokens_supported": 4096,
                "supports_function_calling": True,
                "supports_vision": True,
                "supports_streaming": True,
                "context_window": 128000,
                "llm_metadata": {
                    "description": "GPT-4 Turbo - Vers√£o otimizada do GPT-4",
                    "release_date": "2024-04-09",
                    "capabilities": ["text", "vision", "function_calling"],
                    "best_for": ["An√°lise de documentos", "Programa√ß√£o", "Cria√ß√£o de conte√∫do"]
                }
            },
            {
                "name": "gpt-4",
                "provider": "openai",
                "model_version": "2024-02-01",
                "cost_per_token_input": 0.00003,
                "cost_per_token_output": 0.00006,
                "max_tokens_supported": 8192,
                "supports_function_calling": True,
                "supports_vision": False,
                "supports_streaming": True,
                "context_window": 8192,
                "llm_metadata": {
                    "description": "GPT-4 - Modelo cl√°ssico de alta qualidade",
                    "release_date": "2023-03-14",
                    "capabilities": ["text", "function_calling", "reasoning"],
                    "best_for": ["Tarefas complexas", "An√°lise profunda", "Criatividade"]
                }
            },
            {
                "name": "gpt-3.5-turbo",
                "provider": "openai",
                "model_version": "2024-01-25",
                "cost_per_token_input": 0.0000005,
                "cost_per_token_output": 0.0000015,
                "max_tokens_supported": 4096,
                "supports_function_calling": True,
                "supports_vision": False,
                "supports_streaming": True,
                "context_window": 16385,
                "llm_metadata": {
                    "description": "GPT-3.5 Turbo - Modelo r√°pido e econ√¥mico",
                    "release_date": "2022-11-30",
                    "capabilities": ["text", "function_calling"],
                    "best_for": ["Chat", "Tarefas simples", "Alto volume"]
                }
            },
            {
                "name": "gpt-3.5-turbo-instruct",
                "provider": "openai",
                "model_version": "2023-09-01",
                "cost_per_token_input": 0.0000015,
                "cost_per_token_output": 0.000002,
                "max_tokens_supported": 4096,
                "supports_function_calling": False,
                "supports_vision": False,
                "supports_streaming": True,
                "context_window": 4096,
                "llm_metadata": {
                    "description": "GPT-3.5 Turbo Instruct - Modelo de completa√ß√£o",
                    "release_date": "2023-09-01",
                    "capabilities": ["text"],
                    "best_for": ["Completa√ß√£o de texto", "Gera√ß√£o criativa"]
                }
            },

            # ========================================
            # ANTHROPIC CLAUDE - Fam√≠lia Claude 3.5 e 3
            # ========================================
            {
                "name": "claude-3-5-sonnet-20241022",
                "provider": "anthropic",
                "model_version": "20241022",
                "cost_per_token_input": 0.000003,
                "cost_per_token_output": 0.000015,
                "max_tokens_supported": 8192,
                "supports_function_calling": True,
                "supports_vision": True,
                "supports_streaming": True,
                "context_window": 200000,
                "llm_metadata": {
                    "description": "Claude 3.5 Sonnet - Modelo mais avan√ßado da Anthropic",
                    "release_date": "2024-10-22",
                    "capabilities": ["text", "vision", "function_calling", "reasoning", "code"],
                    "best_for": ["An√°lise complexa", "Programa√ß√£o", "Racioc√≠nio avan√ßado"]
                }
            },
            {
                "name": "claude-3-5-haiku-20241022",
                "provider": "anthropic",
                "model_version": "20241022",
                "cost_per_token_input": 0.00000025,
                "cost_per_token_output": 0.00000125,
                "max_tokens_supported": 8192,
                "supports_function_calling": True,
                "supports_vision": True,
                "supports_streaming": True,
                "context_window": 200000,
                "llm_metadata": {
                    "description": "Claude 3.5 Haiku - Modelo r√°pido e eficiente",
                    "release_date": "2024-10-22",
                    "capabilities": ["text", "vision", "function_calling"],
                    "best_for": ["Respostas r√°pidas", "Alto volume", "Tarefas simples"]
                }
            },
            {
                "name": "claude-3-opus-20240229",
                "provider": "anthropic",
                "model_version": "20240229",
                "cost_per_token_input": 0.000015,
                "cost_per_token_output": 0.000075,
                "max_tokens_supported": 4096,
                "supports_function_calling": True,
                "supports_vision": True,
                "supports_streaming": True,
                "context_window": 200000,
                "llm_metadata": {
                    "description": "Claude 3 Opus - Modelo premium para tarefas complexas",
                    "release_date": "2024-02-29",
                    "capabilities": ["text", "vision", "function_calling", "reasoning"],
                    "best_for": ["An√°lise profunda", "Criatividade", "Tarefas complexas"]
                }
            },
            {
                "name": "claude-3-sonnet-20240229",
                "provider": "anthropic",
                "model_version": "20240229",
                "cost_per_token_input": 0.000003,
                "cost_per_token_output": 0.000015,
                "max_tokens_supported": 4096,
                "supports_function_calling": True,
                "supports_vision": True,
                "supports_streaming": True,
                "context_window": 200000,
                "llm_metadata": {
                    "description": "Claude 3 Sonnet - Equil√≠brio entre performance e custo",
                    "release_date": "2024-02-29",
                    "capabilities": ["text", "vision", "function_calling"],
                    "best_for": ["Uso geral", "An√°lise de documentos", "Programa√ß√£o"]
                }
            },
            {
                "name": "claude-3-haiku-20240307",
                "provider": "anthropic",
                "model_version": "20240307",
                "cost_per_token_input": 0.00000025,
                "cost_per_token_output": 0.00000125,
                "max_tokens_supported": 4096,
                "supports_function_calling": True,
                "supports_vision": True,
                "supports_streaming": True,
                "context_window": 200000,
                "llm_metadata": {
                    "description": "Claude 3 Haiku - Modelo r√°pido e econ√¥mico",
                    "release_date": "2024-03-07",
                    "capabilities": ["text", "vision", "function_calling"],
                    "best_for": ["Respostas r√°pidas", "Chat", "Tarefas simples"]
                }
            },

            # ========================================
            # GOOGLE GEMINI - Fam√≠lia Gemini 2.0 e 1.5
            # ========================================
            {
                "name": "gemini-2.0-flash-exp",
                "provider": "google",
                "model_version": "experimental",
                "cost_per_token_input": 0.0000001,
                "cost_per_token_output": 0.0000004,
                "max_tokens_supported": 8192,
                "supports_function_calling": True,
                "supports_vision": True,
                "supports_streaming": True,
                "context_window": 1000000,
                "llm_metadata": {
                    "description": "Gemini 2.0 Flash - Modelo experimental mais avan√ßado",
                    "release_date": "2024-12-11",
                    "capabilities": ["text", "vision", "function_calling", "reasoning", "multimodal"],
                    "best_for": ["Tarefas multimodais", "Experimenta√ß√£o", "An√°lise avan√ßada"]
                }
            },
            {
                "name": "gemini-1.5-pro",
                "provider": "google",
                "model_version": "latest",
                "cost_per_token_input": 0.0000035,
                "cost_per_token_output": 0.0000105,
                "max_tokens_supported": 8192,
                "supports_function_calling": True,
                "supports_vision": True,
                "supports_streaming": True,
                "context_window": 2000000,
                "llm_metadata": {
                    "description": "Gemini 1.5 Pro - Modelo avan√ßado com contexto extenso",
                    "release_date": "2024-02-15",
                    "capabilities": ["text", "vision", "function_calling", "reasoning"],
                    "best_for": ["An√°lise de documentos longos", "Contexto extenso", "Multimodal"]
                }
            },
            {
                "name": "gemini-1.5-flash",
                "provider": "google",
                "model_version": "latest",
                "cost_per_token_input": 0.000000075,
                "cost_per_token_output": 0.0000003,
                "max_tokens_supported": 8192,
                "supports_function_calling": True,
                "supports_vision": True,
                "supports_streaming": True,
                "context_window": 1000000,
                "llm_metadata": {
                    "description": "Gemini 1.5 Flash - Modelo r√°pido e eficiente",
                    "release_date": "2024-05-14",
                    "capabilities": ["text", "vision", "function_calling"],
                    "best_for": ["Respostas r√°pidas", "Alto volume", "Custo-benef√≠cio"]
                }
            },
            {
                "name": "gemini-1.5-flash-8b",
                "provider": "google",
                "model_version": "latest",
                "cost_per_token_input": 0.0000000375,
                "cost_per_token_output": 0.00000015,
                "max_tokens_supported": 8192,
                "supports_function_calling": True,
                "supports_vision": False,
                "supports_streaming": True,
                "context_window": 1000000,
                "llm_metadata": {
                    "description": "Gemini 1.5 Flash 8B - Modelo ultra-r√°pido e econ√¥mico",
                    "release_date": "2024-10-03",
                    "capabilities": ["text", "function_calling"],
                    "best_for": ["Alto volume", "Tarefas simples", "M√°ximo custo-benef√≠cio"]
                }
            },
            {
                "name": "gemini-1.0-pro",
                "provider": "google",
                "model_version": "latest",
                "cost_per_token_input": 0.0000005,
                "cost_per_token_output": 0.0000015,
                "max_tokens_supported": 8192,
                "supports_function_calling": True,
                "supports_vision": False,
                "supports_streaming": True,
                "context_window": 32768,
                "llm_metadata": {
                    "description": "Gemini 1.0 Pro - Modelo cl√°ssico do Google",
                    "release_date": "2023-12-06",
                    "capabilities": ["text", "function_calling"],
                    "best_for": ["Uso geral", "Chat", "An√°lise de texto"]
                }
            },

            # ========================================
            # GROK (xAI) - Modelos Grok
            # ========================================
            {
                "name": "grok-2-1212",
                "provider": "grok",
                "model_version": "1212",
                "cost_per_token_input": 0.000002,
                "cost_per_token_output": 0.00001,
                "max_tokens_supported": 8192,
                "supports_function_calling": True,
                "supports_vision": True,
                "supports_streaming": True,
                "context_window": 131072,
                "llm_metadata": {
                    "description": "Grok 2 - Modelo mais recente da xAI com humor",
                    "release_date": "2024-12-12",
                    "capabilities": ["text", "vision", "function_calling", "humor"],
                    "best_for": ["Conversas casuais", "An√°lise com humor", "Criatividade"]
                }
            },
            {
                "name": "grok-2-vision-1212",
                "provider": "grok",
                "model_version": "1212",
                "cost_per_token_input": 0.000002,
                "cost_per_token_output": 0.00001,
                "max_tokens_supported": 8192,
                "supports_function_calling": True,
                "supports_vision": True,
                "supports_streaming": True,
                "context_window": 131072,
                "llm_metadata": {
                    "description": "Grok 2 Vision - Vers√£o com capacidades visuais",
                    "release_date": "2024-12-12",
                    "capabilities": ["text", "vision", "function_calling", "humor"],
                    "best_for": ["An√°lise de imagens", "Multimodal", "Criatividade visual"]
                }
            },
            {
                "name": "grok-beta",
                "provider": "grok",
                "model_version": "beta",
                "cost_per_token_input": 0.000005,
                "cost_per_token_output": 0.000015,
                "max_tokens_supported": 4096,
                "supports_function_calling": False,
                "supports_vision": False,
                "supports_streaming": True,
                "context_window": 131072,
                "llm_metadata": {
                    "description": "Grok Beta - Vers√£o experimental",
                    "release_date": "2024-08-13",
                    "capabilities": ["text", "humor"],
                    "best_for": ["Experimenta√ß√£o", "Conversas casuais"]
                }
            },

            # ========================================
            # DEEPSEEK - Modelos especializados
            # ========================================
            {
                "name": "deepseek-chat",
                "provider": "deepseek",
                "model_version": "latest",
                "cost_per_token_input": 0.00000014,
                "cost_per_token_output": 0.00000028,
                "max_tokens_supported": 4096,
                "supports_function_calling": True,
                "supports_vision": False,
                "supports_streaming": True,
                "context_window": 32768,
                "llm_metadata": {
                    "description": "DeepSeek Chat - Modelo conversacional econ√¥mico",
                    "release_date": "2024-01-01",
                    "capabilities": ["text", "function_calling"],
                    "best_for": ["Chat", "Conversas", "Custo baixo"]
                }
            },
            {
                "name": "deepseek-coder",
                "provider": "deepseek",
                "model_version": "latest",
                "cost_per_token_input": 0.00000014,
                "cost_per_token_output": 0.00000028,
                "max_tokens_supported": 4096,
                "supports_function_calling": True,
                "supports_vision": False,
                "supports_streaming": True,
                "context_window": 32768,
                "llm_metadata": {
                    "description": "DeepSeek Coder - Especializado em programa√ß√£o",
                    "release_date": "2024-01-01",
                    "capabilities": ["text", "function_calling", "code"],
                    "best_for": ["Programa√ß√£o", "Debug", "An√°lise de c√≥digo"]
                }
            },
            {
                "name": "deepseek-reasoner",
                "provider": "deepseek",
                "model_version": "latest",
                "cost_per_token_input": 0.00000055,
                "cost_per_token_output": 0.0000022,
                "max_tokens_supported": 8192,
                "supports_function_calling": True,
                "supports_vision": False,
                "supports_streaming": True,
                "context_window": 65536,
                "llm_metadata": {
                    "description": "DeepSeek Reasoner - Especializado em racioc√≠nio",
                    "release_date": "2024-11-28",
                    "capabilities": ["text", "function_calling", "reasoning"],
                    "best_for": ["Racioc√≠nio l√≥gico", "Matem√°tica", "An√°lise complexa"]
                }
            },

            # ========================================
            # META LLAMA - Fam√≠lia Llama 3.x
            # ========================================
            {
                "name": "llama-3.3-70b-instruct",
                "provider": "llama",
                "model_version": "3.3",
                "cost_per_token_input": 0.00000059,
                "cost_per_token_output": 0.00000079,
                "max_tokens_supported": 8192,
                "supports_function_calling": True,
                "supports_vision": False,
                "supports_streaming": True,
                "context_window": 131072,
                "llm_metadata": {
                    "description": "Llama 3.3 70B Instruct - Modelo mais recente da Meta",
                    "release_date": "2024-12-06",
                    "capabilities": ["text", "function_calling", "reasoning"],
                    "best_for": ["Instru√ß√µes complexas", "Racioc√≠nio", "Open source"]
                }
            },
            {
                "name": "llama-3.2-90b-vision-instruct",
                "provider": "llama",
                "model_version": "3.2",
                "cost_per_token_input": 0.0000009,
                "cost_per_token_output": 0.0000009,
                "max_tokens_supported": 8192,
                "supports_function_calling": True,
                "supports_vision": True,
                "supports_streaming": True,
                "context_window": 131072,
                "llm_metadata": {
                    "description": "Llama 3.2 90B Vision - Modelo multimodal",
                    "release_date": "2024-09-25",
                    "capabilities": ["text", "vision", "function_calling"],
                    "best_for": ["An√°lise visual", "Multimodal", "Open source"]
                }
            },
            {
                "name": "llama-3.2-11b-vision-instruct",
                "provider": "llama",
                "model_version": "3.2",
                "cost_per_token_input": 0.00000018,
                "cost_per_token_output": 0.00000018,
                "max_tokens_supported": 8192,
                "supports_function_calling": True,
                "supports_vision": True,
                "supports_streaming": True,
                "context_window": 131072,
                "llm_metadata": {
                    "description": "Llama 3.2 11B Vision - Modelo compacto com vis√£o",
                    "release_date": "2024-09-25",
                    "capabilities": ["text", "vision", "function_calling"],
                    "best_for": ["Vis√£o computacional", "Efici√™ncia", "Open source"]
                }
            },
            {
                "name": "llama-3.1-405b-instruct",
                "provider": "llama",
                "model_version": "3.1",
                "cost_per_token_input": 0.000002,
                "cost_per_token_output": 0.000002,
                "max_tokens_supported": 4096,
                "supports_function_calling": True,
                "supports_vision": False,
                "supports_streaming": True,
                "context_window": 131072,
                "llm_metadata": {
                    "description": "Llama 3.1 405B - Maior modelo da Meta",
                    "release_date": "2024-07-23",
                    "capabilities": ["text", "function_calling", "reasoning"],
                    "best_for": ["Tarefas complexas", "Racioc√≠nio avan√ßado", "Open source"]
                }
            },
            {
                "name": "llama-3.1-70b-instruct",
                "provider": "llama",
                "model_version": "3.1",
                "cost_per_token_input": 0.00000059,
                "cost_per_token_output": 0.00000079,
                "max_tokens_supported": 8192,
                "supports_function_calling": True,
                "supports_vision": False,
                "supports_streaming": True,
                "context_window": 131072,
                "llm_metadata": {
                    "description": "Llama 3.1 70B - Modelo equilibrado",
                    "release_date": "2024-07-23",
                    "capabilities": ["text", "function_calling"],
                    "best_for": ["Uso geral", "Custo-benef√≠cio", "Open source"]
                }
            },
            {
                "name": "llama-3.1-8b-instruct",
                "provider": "llama",
                "model_version": "3.1",
                "cost_per_token_input": 0.00000018,
                "cost_per_token_output": 0.00000018,
                "max_tokens_supported": 8192,
                "supports_function_calling": True,
                "supports_vision": False,
                "supports_streaming": True,
                "context_window": 131072,
                "llm_metadata": {
                    "description": "Llama 3.1 8B - Modelo compacto e r√°pido",
                    "release_date": "2024-07-23",
                    "capabilities": ["text", "function_calling"],
                    "best_for": ["Tarefas simples", "Velocidade", "Open source"]
                }
            },

            # ========================================
            # MISTRAL AI - Modelos Mistral
            # ========================================
            {
                "name": "mistral-large-2411",
                "provider": "mistral",
                "model_version": "2411",
                "cost_per_token_input": 0.000002,
                "cost_per_token_output": 0.000006,
                "max_tokens_supported": 8192,
                "supports_function_calling": True,
                "supports_vision": False,
                "supports_streaming": True,
                "context_window": 128000,
                "llm_metadata": {
                    "description": "Mistral Large - Modelo premium da Mistral AI",
                    "release_date": "2024-11-01",
                    "capabilities": ["text", "function_calling", "reasoning"],
                    "best_for": ["Tarefas complexas", "Multil√≠ngue", "Racioc√≠nio"]
                }
            },
            {
                "name": "mistral-small-2409",
                "provider": "mistral",
                "model_version": "2409",
                "cost_per_token_input": 0.0000002,
                "cost_per_token_output": 0.0000006,
                "max_tokens_supported": 8192,
                "supports_function_calling": True,
                "supports_vision": False,
                "supports_streaming": True,
                "context_window": 128000,
                "llm_metadata": {
                    "description": "Mistral Small - Modelo eficiente e econ√¥mico",
                    "release_date": "2024-09-01",
                    "capabilities": ["text", "function_calling"],
                    "best_for": ["Uso geral", "Custo-benef√≠cio", "Multil√≠ngue"]
                }
            },
            {
                "name": "pixtral-12b-2409",
                "provider": "mistral",
                "model_version": "2409",
                "cost_per_token_input": 0.00000015,
                "cost_per_token_output": 0.00000015,
                "max_tokens_supported": 8192,
                "supports_function_calling": True,
                "supports_vision": True,
                "supports_streaming": True,
                "context_window": 128000,
                "llm_metadata": {
                    "description": "Pixtral 12B - Modelo multimodal da Mistral",
                    "release_date": "2024-09-01",
                    "capabilities": ["text", "vision", "function_calling"],
                    "best_for": ["An√°lise visual", "Multimodal", "Efici√™ncia"]
                }
            },

            # ========================================
            # COHERE - Modelos Command
            # ========================================
            {
                "name": "command-r-plus-08-2024",
                "provider": "cohere",
                "model_version": "08-2024",
                "cost_per_token_input": 0.0000025,
                "cost_per_token_output": 0.00001,
                "max_tokens_supported": 4096,
                "supports_function_calling": True,
                "supports_vision": False,
                "supports_streaming": True,
                "context_window": 128000,
                "llm_metadata": {
                    "description": "Command R+ - Modelo premium da Cohere",
                    "release_date": "2024-08-01",
                    "capabilities": ["text", "function_calling", "reasoning"],
                    "best_for": ["RAG", "Busca", "An√°lise de documentos"]
                }
            },
            {
                "name": "command-r-08-2024",
                "provider": "cohere",
                "model_version": "08-2024",
                "cost_per_token_input": 0.00000015,
                "cost_per_token_output": 0.0000006,
                "max_tokens_supported": 4096,
                "supports_function_calling": True,
                "supports_vision": False,
                "supports_streaming": True,
                "context_window": 128000,
                "llm_metadata": {
                    "description": "Command R - Modelo b√°sico da Cohere",
                    "release_date": "2024-08-01",
                    "capabilities": ["text", "function_calling"],
                    "best_for": ["RAG", "Busca", "An√°lise de documentos"]
                }
            },

            # ========================================
            # OPENAI - Modelos adicionais e finetuned
            # ========================================
            {
                "name": "gpt-4",
                "provider": "openai",
                "model_version": "2023-03-14",
                "cost_per_token_input": 0.00003,
                "cost_per_token_output": 0.00006,
                "max_tokens_supported": 8192,
                "supports_function_calling": True,
                "supports_vision": False,
                "supports_streaming": True,
                "context_window": 8192,
                "llm_metadata": {
                    "description": "GPT-4 - Modelo cl√°ssico OpenAI",
                    "release_date": "2023-03-14",
                    "capabilities": ["text", "function_calling"],
                    "best_for": ["Tarefas complexas", "An√°lise profunda"]
                }
            },
            {
                "name": "gpt-3.5-turbo-16k",
                "provider": "openai",
                "model_version": "2023-06-13",
                "cost_per_token_input": 0.000003,
                "cost_per_token_output": 0.000004,
                "max_tokens_supported": 16384,
                "supports_function_calling": True,
                "supports_vision": False,
                "supports_streaming": True,
                "context_window": 16384,
                "llm_metadata": {
                    "description": "GPT-3.5 Turbo 16k - Contexto expandido",
                    "release_date": "2023-06-13",
                    "capabilities": ["text", "function_calling"],
                    "best_for": ["Documentos longos", "Chat"]
                }
            },

            # ========================================
            # ANTHROPIC - Modelos Claude 2.x, 1.x
            # ========================================
            {
                "name": "claude-2.1",
                "provider": "anthropic",
                "model_version": "2023-11-21",
                "cost_per_token_input": 0.000008,
                "cost_per_token_output": 0.000024,
                "max_tokens_supported": 200000,
                "supports_function_calling": False,
                "supports_vision": False,
                "supports_streaming": True,
                "context_window": 200000,
                "llm_metadata": {
                    "description": "Claude 2.1 - Modelo intermedi√°rio da Anthropic",
                    "release_date": "2023-11-21",
                    "capabilities": ["text"],
                    "best_for": ["An√°lise de texto", "Documentos longos"]
                }
            },
            {
                "name": "claude-2.0",
                "provider": "anthropic",
                "model_version": "2023-07-11",
                "cost_per_token_input": 0.000008,
                "cost_per_token_output": 0.000024,
                "max_tokens_supported": 100000,
                "supports_function_calling": False,
                "supports_vision": False,
                "supports_streaming": True,
                "context_window": 100000,
                "llm_metadata": {
                    "description": "Claude 2.0 - Modelo anterior da Anthropic",
                    "release_date": "2023-07-11",
                    "capabilities": ["text"],
                    "best_for": ["Documentos longos", "Chat"]
                }
            },

            # ========================================
            # GOOGLE - Gemini Ultra, Nano, Pro, Flash
            # ========================================
            {
                "name": "gemini-1.0-ultra",
                "provider": "google",
                "model_version": "2024-01-01",
                "cost_per_token_input": 0.00001,
                "cost_per_token_output": 0.00003,
                "max_tokens_supported": 32768,
                "supports_function_calling": True,
                "supports_vision": True,
                "supports_streaming": True,
                "context_window": 32768,
                "llm_metadata": {
                    "description": "Gemini 1.0 Ultra - Modelo premium Google",
                    "release_date": "2024-01-01",
                    "capabilities": ["text", "vision", "function_calling"],
                    "best_for": ["Tarefas avan√ßadas", "Multimodal"]
                }
            },
            {
                "name": "gemini-1.0-nano",
                "provider": "google",
                "model_version": "2024-01-01",
                "cost_per_token_input": 0.0000001,
                "cost_per_token_output": 0.0000004,
                "max_tokens_supported": 8192,
                "supports_function_calling": False,
                "supports_vision": False,
                "supports_streaming": True,
                "context_window": 8192,
                "llm_metadata": {
                    "description": "Gemini 1.0 Nano - Modelo leve Google",
                    "release_date": "2024-01-01",
                    "capabilities": ["text"],
                    "best_for": ["Dispositivos m√≥veis", "Edge"]
                }
            },

            # ========================================
            # META - Llama 2.x, CodeLlama, Llama Guard
            # ========================================
            {
                "name": "llama-2-70b-chat",
                "provider": "llama",
                "model_version": "2.0",
                "cost_per_token_input": 0.0000005,
                "cost_per_token_output": 0.0000005,
                "max_tokens_supported": 4096,
                "supports_function_calling": False,
                "supports_vision": False,
                "supports_streaming": True,
                "context_window": 4096,
                "llm_metadata": {
                    "description": "Llama 2 70B Chat - Modelo open source Meta",
                    "release_date": "2023-07-18",
                    "capabilities": ["text"],
                    "best_for": ["Chat", "Open source"]
                }
            },
            {
                "name": "codellama-70b-instruct",
                "provider": "llama",
                "model_version": "2.0",
                "cost_per_token_input": 0.0000006,
                "cost_per_token_output": 0.0000006,
                "max_tokens_supported": 4096,
                "supports_function_calling": True,
                "supports_vision": False,
                "supports_streaming": True,
                "context_window": 4096,
                "llm_metadata": {
                    "description": "CodeLlama 70B Instruct - Modelo de c√≥digo Meta",
                    "release_date": "2023-08-24",
                    "capabilities": ["text", "code", "function_calling"],
                    "best_for": ["Programa√ß√£o", "Open source"]
                }
            },

            # ========================================
            # MISTRAL - Codestral, LeChat, Tiny, etc
            # ========================================
            {
                "name": "codestral-22b",
                "provider": "mistral",
                "model_version": "2024-06-01",
                "cost_per_token_input": 0.000001,
                "cost_per_token_output": 0.000001,
                "max_tokens_supported": 32000,
                "supports_function_calling": True,
                "supports_vision": False,
                "supports_streaming": True,
                "context_window": 32000,
                "llm_metadata": {
                    "description": "Codestral 22B - Modelo de c√≥digo Mistral",
                    "release_date": "2024-06-01",
                    "capabilities": ["text", "code", "function_calling"],
                    "best_for": ["Programa√ß√£o", "Racioc√≠nio"]
                }
            },
            {
                "name": "lechat-7b",
                "provider": "mistral",
                "model_version": "2024-05-01",
                "cost_per_token_input": 0.0000002,
                "cost_per_token_output": 0.0000002,
                "max_tokens_supported": 8192,
                "supports_function_calling": True,
                "supports_vision": False,
                "supports_streaming": True,
                "context_window": 8192,
                "llm_metadata": {
                    "description": "LeChat 7B - Chatbot open source Mistral",
                    "release_date": "2024-05-01",
                    "capabilities": ["text", "function_calling"],
                    "best_for": ["Chat", "Open source"]
                }
            },

            # ========================================
            # COHERE - Embed, Command, etc
            # ========================================
            {
                "name": "embed-multilingual-v3.0",
                "provider": "cohere",
                "model_version": "2024-06-01",
                "cost_per_token_input": 0.0000001,
                "cost_per_token_output": 0.0000001,
                "max_tokens_supported": 4096,
                "supports_function_calling": False,
                "supports_vision": False,
                "supports_streaming": True,
                "context_window": 4096,
                "llm_metadata": {
                    "description": "Cohere Embed Multilingual v3.0",
                    "release_date": "2024-06-01",
                    "capabilities": ["text", "embedding"],
                    "best_for": ["Embeddings", "Multil√≠ngue"]
                }
            },

            # ========================================
            # AWS BEDROCK - Amazon Titan, Jurassic, Claude Bedrock
            # ========================================
            {
                "name": "amazon-titan-text-express-v1",
                "provider": "aws-bedrock",
                "model_version": "2024-01-01",
                "cost_per_token_input": 0.000001,
                "cost_per_token_output": 0.000001,
                "max_tokens_supported": 8192,
                "supports_function_calling": True,
                "supports_vision": False,
                "supports_streaming": True,
                "context_window": 8192,
                "llm_metadata": {
                    "description": "Amazon Titan Text Express v1",
                    "release_date": "2024-01-01",
                    "capabilities": ["text", "function_calling"],
                    "best_for": ["AWS Bedrock", "Enterprise"]
                }
            },

            # ========================================
            # AZURE OPENAI - Modelos exclusivos Azure
            # ========================================
            {
                "name": "gpt-4-azure",
                "provider": "azure-openai",
                "model_version": "2024-01-01",
                "cost_per_token_input": 0.00003,
                "cost_per_token_output": 0.00006,
                "max_tokens_supported": 8192,
                "supports_function_calling": True,
                "supports_vision": False,
                "supports_streaming": True,
                "context_window": 8192,
                "llm_metadata": {
                    "description": "GPT-4 Azure - Modelo exclusivo Azure OpenAI",
                    "release_date": "2024-01-01",
                    "capabilities": ["text", "function_calling"],
                    "best_for": ["Azure", "Enterprise"]
                }
            },

            # ========================================
            # OLLAMA/LOCALAI - Modelos open source populares
            # ========================================
            {
                "name": "phi-3-mini",
                "provider": "ollama",
                "model_version": "2024-05-01",
                "cost_per_token_input": 0.0,
                "cost_per_token_output": 0.0,
                "max_tokens_supported": 128000,
                "supports_function_calling": True,
                "supports_vision": False,
                "supports_streaming": True,
                "context_window": 128000,
                "llm_metadata": {
                    "description": "Phi-3 Mini - Modelo open source Microsoft",
                    "release_date": "2024-05-01",
                    "capabilities": ["text", "function_calling"],
                    "best_for": ["Open source", "Edge"]
                }
            },
            {
                "name": "dbrx-instruct",
                "provider": "ollama",
                "model_version": "2024-04-01",
                "cost_per_token_input": 0.0,
                "cost_per_token_output": 0.0,
                "max_tokens_supported": 128000,
                "supports_function_calling": True,
                "supports_vision": False,
                "supports_streaming": True,
                "context_window": 128000,
                "llm_metadata": {
                    "description": "DBRX Instruct - Modelo open source Databricks",
                    "release_date": "2024-04-01",
                    "capabilities": ["text", "function_calling"],
                    "best_for": ["Open source", "Enterprise"]
                }
            },

            # ========================================
            # HUGGINGFACE - Falcon, Bloom, MPT, etc
            # ========================================
            {
                "name": "falcon-180b",
                "provider": "huggingface",
                "model_version": "2023-09-01",
                "cost_per_token_input": 0.0,
                "cost_per_token_output": 0.0,
                "max_tokens_supported": 8192,
                "supports_function_calling": False,
                "supports_vision": False,
                "supports_streaming": True,
                "context_window": 8192,
                "llm_metadata": {
                    "description": "Falcon 180B - Modelo open source HuggingFace",
                    "release_date": "2023-09-01",
                    "capabilities": ["text"],
                    "best_for": ["Open source", "Pesquisa"]
                }
            },

            # ========================================
            # GROQ, PERPLEXITY, TOGETHER, OPENROUTER, ETC
            # ========================================
            {
                "name": "mixtral-8x22b",
                "provider": "groq",
                "model_version": "2024-06-01",
                "cost_per_token_input": 0.000001,
                "cost_per_token_output": 0.000001,
                "max_tokens_supported": 128000,
                "supports_function_calling": True,
                "supports_vision": False,
                "supports_streaming": True,
                "context_window": 128000,
                "llm_metadata": {
                    "description": "Mixtral 8x22B - Modelo Groq",
                    "release_date": "2024-06-01",
                    "capabilities": ["text", "function_calling"],
                    "best_for": ["API p√∫blica", "Performance"]
                }
            },

            # ========================================
            # MODELOS REGIONAIS/EXPERIMENTAIS
            # ========================================
            {
                "name": "yi-34b-chat",
                "provider": "yi",
                "model_version": "2024-05-01",
                "cost_per_token_input": 0.0,
                "cost_per_token_output": 0.0,
                "max_tokens_supported": 128000,
                "supports_function_calling": True,
                "supports_vision": False,
                "supports_streaming": True,
                "context_window": 128000,
                "llm_metadata": {
                    "description": "Yi 34B Chat - Modelo regional avan√ßado",
                    "release_date": "2024-05-01",
                    "capabilities": ["text", "function_calling"],
                    "best_for": ["Chin√™s", "Pesquisa"]
                }
            },
            {
                "name": "qwen-72b-chat",
                "provider": "qwen",
                "model_version": "2024-05-01",
                "cost_per_token_input": 0.0,
                "cost_per_token_output": 0.0,
                "max_tokens_supported": 128000,
                "supports_function_calling": True,
                "supports_vision": True,
                "supports_streaming": True,
                "context_window": 128000,
                "llm_metadata": {
                    "description": "Qwen 72B Chat - Modelo regional multimodal",
                    "release_date": "2024-05-01",
                    "capabilities": ["text", "vision", "function_calling"],
                    "best_for": ["Chin√™s", "Multimodal"]
                }
            },
        ]

        # Atualiza√ß√£o inteligente: update se existe, insert se n√£o existe
        created, updated = 0, 0
        for model_data in llms_data:
            existing = db.query(LLM).filter(
                LLM.provider == model_data["provider"],
                LLM.name == model_data["name"],
                LLM.model_version == model_data["model_version"]
            ).first()
            if existing:
                # Atualizar apenas campos relevantes
                for field, value in model_data.items():
                    if field not in ["id", "created_at"]:
                        setattr(existing, field, value)
                updated += 1
            else:
                model = LLM(**model_data)
                db.add(model)
                created += 1
        db.commit()
        print(f"‚úÖ LLMs inseridos: {created} | atualizados: {updated}")

    except Exception as e:
        print(f"‚ùå Erro ao popular LLMs: {e}")
    finally:
        db.close()


if __name__ == "__main__":
    populate_complete_llms()
