"""
Servi√ßo de Execu√ß√£o de Workflows
Criado por Jos√© - um desenvolvedor Full Stack
Engine completa de execu√ß√£o em tempo real com todas as funcionalidades
"""

import asyncio
import json
import logging
import re
import time
import traceback
import uuid
from concurrent.futures import ThreadPoolExecutor
from datetime import datetime, timedelta
from typing import Any, Dict, List, Optional, Union, Tuple
import threading

from sqlalchemy import asc, desc, func, or_, text
from sqlalchemy.orm import Session

from src.synapse.models.workflow_execution import (
    WorkflowExecution,
    NodeExecution,
    ExecutionQueue,
    ExecutionMetrics,
    ExecutionStatus,
    NodeExecutionStatus,
)
from src.synapse.models.workflow import Workflow
from src.synapse.models.node import Node
from src.synapse.schemas.workflow_execution import (
    ExecutionCreate,
    ExecutionResponse,
    NodeExecutionResponse,
    ExecutionStats,
    ExecutionFilter,
)
from src.synapse.database import get_db
from src.synapse.core.websockets.manager import ConnectionManager
from src.synapse.services.variable_service import VariableService
from src.synapse.exceptions import DatabaseError


# Configura√ß√£o de logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class ExecutionEngine:
    """
    Engine principal de execu√ß√£o de workflows
    Gerencia todo o ciclo de vida de execu√ß√£o
    """

    def __init__(self, websocket_manager: Optional[ConnectionManager] = None):
        self.websocket_manager = websocket_manager
        self.variable_service = VariableService()
        self.executor = ThreadPoolExecutor(max_workers=10)
        self.running_executions: Dict[str, asyncio.Task] = {}
        self.execution_lock = threading.Lock()
        self.is_running = False
        self.queue_processor_task = None

    async def start(self) -> None:
        """Inicia a engine de execu√ß√£o"""
        if self.is_running:
            return

        self.is_running = True
        self.queue_processor_task = asyncio.create_task(
            self._process_queue()
        )  # type: ignore
        logger.info("üöÄ Engine de Execu√ß√£o iniciada com sucesso!")

    async def stop(self) -> None:
        """Para a engine de execu√ß√£o"""
        self.is_running = False

        # Cancela o processador de fila
        if self.queue_processor_task:
            self.queue_processor_task.cancel()

        # Cancela execu√ß√µes em andamento
        for execution_id, task in self.running_executions.items():
            task.cancel()
            logger.info("Cancelando execu√ß√£o %s", execution_id)

        # Aguarda finaliza√ß√£o
        await asyncio.gather(
            *self.running_executions.values(), return_exceptions=True
        )
        self.running_executions.clear()

        logger.info("üõë Engine de Execu√ß√£o parada com sucesso!")

    async def create_execution(
        self, db: Session, execution_data: ExecutionCreate, user_id: int
    ) -> ExecutionResponse:
        """
        Cria uma nova execu√ß√£o de workflow
        """
        try:
            # Valida o workflow
            workflow = (
                db.query(Workflow)
                .filter(Workflow.id == execution_data.workflow_id)
                .first()
            )
            if not workflow:
                raise ValueError(
                    f"Workflow {execution_data.workflow_id} n√£o encontrado"
                )

            # Valida permiss√µes do usu√°rio
            if workflow.user_id != user_id:
                raise ValueError(
                    "Usu√°rio n√£o tem permiss√£o para executar este workflow"
                )
            # Carrega vari√°veis do usu√°rio se necess√°rio
            user_variables = {}
            if execution_data.variables is None:
                user_variables = self.variable_service.get_user_env_dict(
                    db, user_id
                )
            else:
                user_variables = execution_data.variables

            # Valida o workflow antes da execu√ß√£o
            validation = await self._validate_workflow(
                db, workflow, user_variables
            )
            if not validation["is_valid"]:
                raise ValueError(
                    f"Workflow inv√°lido: {', '.join(validation['errors'])}"
                )

            # Cria a execu√ß√£o
            execution = WorkflowExecution(
                execution_id=str(uuid.uuid4()),
                workflow_id=execution_data.workflow_id,
                user_id=user_id,
                status=ExecutionStatus.PENDING,
                input_data=execution_data.input_data,
                context_data=execution_data.context_data,
                variables=user_variables,
                priority=execution_data.priority,
                total_nodes=validation["total_nodes"],
                timeout_at=(
                    datetime.utcnow()
                    + timedelta(seconds=execution_data.timeout_seconds)
                    if execution_data.timeout_seconds
                    else None
                ),
                estimated_duration=validation.get(
                    "estimated_duration_seconds"
                ),
                max_retries=execution_data.max_retries,
                auto_retry=execution_data.auto_retry,
                notify_on_completion=execution_data.notify_on_completion,
                notify_on_failure=execution_data.notify_on_failure,
                tags=execution_data.tags,
                metadata=execution_data.metadata,
            )

            db.add(execution)
            db.commit()
            db.refresh(execution)

            # Cria execu√ß√µes de n√≥s
            await self._create_node_executions(db, execution, workflow)

            # Adiciona √† fila de execu√ß√£o
            await self._add_to_queue(db, execution)

            # Notifica via WebSocket
            if self.websocket_manager:
                await self.websocket_manager.send_to_user(
                    {
                        "type": "execution_created",
                        "execution_id": execution.execution_id,
                        "workflow_id": execution.workflow_id,
                        "status": execution.status.value,
                    },
                    str(user_id),
                )

            logger.info(
                "‚úÖ Execu√ß√£o %s criada com sucesso", execution.execution_id
            )
            return ExecutionResponse.from_orm(execution)

        except (ValueError, DatabaseError) as e:
            logger.error("‚ùå Erro ao criar execu√ß√£o: %s", str(e))
            db.rollback()
            raise
        except Exception as e:
            logger.error("‚ùå Erro inesperado ao criar execu√ß√£o: %s", str(e))
            db.rollback()
            raise DatabaseError(
                f"Erro interno ao criar execu√ß√£o: {str(e)}"
            ) from e

    async def start_execution(
        self, db: Session, execution_id: str, user_id: int
    ) -> bool:
        """
        Inicia uma execu√ß√£o espec√≠fica
        """
        try:
            execution = (
                db.query(WorkflowExecution)
                .filter(
                    WorkflowExecution.execution_id == execution_id,
                    WorkflowExecution.user_id == user_id,
                )
                .first()
            )

            if not execution:
                raise ValueError(f"Execu√ß√£o {execution_id} n√£o encontrada")

            if execution.status != ExecutionStatus.PENDING:
                raise ValueError(f"Execu√ß√£o {execution_id} n√£o est√° pendente")

            # Inicia a execu√ß√£o
            task = asyncio.create_task(self._execute_workflow(db, execution))

            with self.execution_lock:
                self.running_executions[execution_id] = task

            logger.info("üöÄ Execu√ß√£o %s iniciada", execution_id)
            return True

        except (ValueError, DatabaseError) as e:
            logger.error(
                "‚ùå Erro ao iniciar execu√ß√£o %s: %s", execution_id, str(e)
            )
            return False
        except Exception as e:
            logger.error(
                "‚ùå Erro inesperado ao iniciar execu√ß√£o %s: %s",
                execution_id, str(e)
            )
            return False

    async def cancel_execution(
        self,
        db: Session,
        execution_id: str,
        user_id: int,
        reason: Optional[str] = None,
    ) -> bool:
        """
        Cancela uma execu√ß√£o
        """
        try:
            execution = (
                db.query(WorkflowExecution)
                .filter(
                    WorkflowExecution.execution_id == execution_id,
                    WorkflowExecution.user_id == user_id,
                )
                .first()
            )

            if not execution:
                raise ValueError(f"Execu√ß√£o {execution_id} n√£o encontrada")

            # Cancela a task se estiver rodando
            with self.execution_lock:
                if execution_id in self.running_executions:
                    self.running_executions[execution_id].cancel()
                    del self.running_executions[execution_id]

            # Atualiza status no banco
            execution.status = ExecutionStatus.CANCELLED  # type: ignore
            execution.completed_at = datetime.utcnow()  # type: ignore
            execution.error_message = (  # type: ignore
                reason or "Execu√ß√£o cancelada pelo usu√°rio"
            )

            # Cancela n√≥s em execu√ß√£o
            db.query(NodeExecution).filter(
                NodeExecution.workflow_execution_id == execution.id,
                NodeExecution.status.in_(
                    [NodeExecutionStatus.PENDING, NodeExecutionStatus.RUNNING]
                ),
            ).update(
                {
                    "status": NodeExecutionStatus.SKIPPED,
                    "completed_at": datetime.utcnow(),
                    "error_message": "Cancelado junto com o workflow",
                }
            )

            db.commit()

            # Notifica via WebSocket
            if self.websocket_manager:
                await self.websocket_manager.send_to_user(
                    {
                        "type": "execution_cancelled",
                        "execution_id": execution_id,
                        "reason": reason,
                    },
                    str(user_id),
                )

            logger.info("üõë Execu√ß√£o %s cancelada", execution_id)
            return True

        except (ValueError, DatabaseError) as e:
            logger.error(
                "‚ùå Erro ao cancelar execu√ß√£o %s: %s", execution_id, str(e)
            )
            return False
        except Exception as e:
            logger.error(
                "‚ùå Erro inesperado ao cancelar execu√ß√£o %s: %s",
                execution_id, str(e)
            )
            return False

    async def retry_execution(
        self, db: Session, execution_id: str, user_id: int
    ) -> bool:
        """
        Reinicia uma execu√ß√£o que falhou
        """
        try:
            execution = (
                db.query(WorkflowExecution)
                .filter(
                    WorkflowExecution.execution_id == execution_id,
                    WorkflowExecution.user_id == user_id,
                )
                .first()
            )

            if not execution:
                raise ValueError(f"Execu√ß√£o {execution_id} n√£o encontrada")

            if execution.status not in [
                ExecutionStatus.FAILED,
                ExecutionStatus.CANCELLED,
                ExecutionStatus.TIMEOUT,
            ]:
                raise ValueError(
                    f"Execu√ß√£o {execution_id} n√£o pode ser reiniciada"
                )

            if execution.retry_count >= execution.max_retries:
                raise ValueError(
                    "Execu√ß√£o %s excedeu o n√∫mero m√°ximo de "
                    "tentativas" % execution_id
                )

            # Reset da execu√ß√£o
            execution.status = ExecutionStatus.PENDING  # type: ignore
            execution.retry_count += 1  # type: ignore
            execution.started_at = None  # type: ignore
            execution.completed_at = None  # type: ignore
            execution.error_message = None  # type: ignore
            execution.error_details = None  # type: ignore
            execution.completed_nodes = 0  # type: ignore
            execution.failed_nodes = 0  # type: ignore
            execution.progress_percentage = 0  # type: ignore

            # Reset dos n√≥s
            db.query(NodeExecution).filter(
                NodeExecution.workflow_execution_id == execution.id
            ).update(
                {
                    "status": NodeExecutionStatus.PENDING,
                    "started_at": None,
                    "completed_at": None,
                    "error_message": None,
                    "error_details": None,
                    "output_data": None,
                    "retry_count": 0,
                }
            )

            db.commit()

            # Adiciona novamente √† fila
            await self._add_to_queue(db, execution)

            logger.info(
                "üîÑ Execu√ß√£o %s reiniciada (tentativa %s)",
                execution_id,
                execution.retry_count,
            )
            return True

        except (ValueError, DatabaseError) as e:
            logger.error(
                "‚ùå Erro ao reiniciar execu√ß√£o %s: %s", execution_id, str(e)
            )
            return False
        except Exception as e:
            logger.error(
                "‚ùå Erro inesperado ao reiniciar execu√ß√£o %s: %s",
                execution_id, str(e)
            )
            return False

    async def get_execution_status(
        self, db: Session, execution_id: str, user_id: int
    ) -> Optional[ExecutionResponse]:
        """
        Obt√©m o status atual de uma execu√ß√£o
        """
        execution = (
            db.query(WorkflowExecution)
            .filter(
                WorkflowExecution.execution_id == execution_id,
                WorkflowExecution.user_id == user_id,
            )
            .first()
        )

        if not execution:
            return None

        return ExecutionResponse.from_orm(execution)

    async def get_node_executions(
        self, db: Session, execution_id: str, user_id: int
    ) -> List[NodeExecutionResponse]:
        """
        Obt√©m as execu√ß√µes de n√≥s de um workflow
        """
        execution = (
            db.query(WorkflowExecution)
            .filter(
                WorkflowExecution.execution_id == execution_id,
                WorkflowExecution.user_id == user_id,
            )
            .first()
        )

        if not execution:
            return []

        node_executions = (
            db.query(NodeExecution)
            .filter(NodeExecution.workflow_execution_id == execution.id)
            .order_by(NodeExecution.execution_order)
            .all()
        )

        return [NodeExecutionResponse.from_orm(ne) for ne in node_executions]

    async def get_execution_logs(
        self, db: Session, execution_id: str, user_id: int
    ) -> Dict[str, Any]:
        """
        Obt√©m os logs detalhados de uma execu√ß√£o
        """
        execution = (
            db.query(WorkflowExecution)
            .filter(
                WorkflowExecution.execution_id == execution_id,
                WorkflowExecution.user_id == user_id,
            )
            .first()
        )

        if not execution:
            return {}

        node_executions = (
            db.query(NodeExecution)
            .filter(NodeExecution.workflow_execution_id == execution.id)
            .order_by(NodeExecution.execution_order)
            .all()
        )

        return {
            "execution": {
                "id": execution.execution_id,
                "status": execution.status.value,
                "log": execution.execution_log,
                "error": execution.error_message,
                "debug": execution.debug_info,
            },
            "nodes": [
                {
                    "key": ne.node_key,
                    "status": ne.status.value,
                    "log": ne.execution_log,
                    "error": ne.error_message,
                    "debug": ne.debug_info,
                    "duration_ms": ne.duration_ms,
                }
                for ne in node_executions
            ],
        }

    async def get_execution_metrics(
        self, db: Session, execution_id: str, user_id: int
    ) -> List[Dict[str, Any]]:
        """
        Obt√©m m√©tricas de uma execu√ß√£o
        """
        execution = (
            db.query(WorkflowExecution)
            .filter(
                WorkflowExecution.execution_id == execution_id,
                WorkflowExecution.user_id == user_id,
            )
            .first()
        )

        if not execution:
            return []

        metrics = (
            db.query(ExecutionMetrics)
            .filter(ExecutionMetrics.workflow_execution_id == execution.id)
            .all()
        )

        return [
            {
                "type": m.metric_type,
                "name": m.metric_name,
                "value": m.value_numeric
                or m.value_float
                or m.value_text
                or m.value_json,
                "context": m.context,
                "measured_at": m.measured_at,
            }
            for m in metrics
        ]

    async def _process_queue(self) -> None:
        """
        Processador principal da fila de execu√ß√£o
        """
        while self.is_running:
            try:
                # Usa o generator get_db corretamente
                db_gen = get_db()
                db = next(db_gen)

                execution_id = None
                user_id = None

                try:
                    # Busca pr√≥xima execu√ß√£o na fila
                    queue_item = (
                        db.query(ExecutionQueue)
                        .filter(
                            ExecutionQueue.status == "queued",
                            or_(
                                ExecutionQueue.scheduled_at.is_(None),
                                ExecutionQueue.scheduled_at
                                <= datetime.utcnow(),
                            ),
                        )
                        .order_by(
                            desc(ExecutionQueue.priority),
                            asc(ExecutionQueue.created_at),
                        )
                        .first()
                    )

                    if queue_item:
                        # Marca como processando
                        queue_item.status = "processing"
                        queue_item.started_at = datetime.utcnow()
                        queue_item.worker_id = f"worker-{uuid.uuid4().hex[:8]}"
                        db.commit()

                        # Pega dados da execu√ß√£o antes de fechar a sess√£o
                        execution_id = (
                            queue_item.workflow_execution.execution_id
                        )
                        user_id = queue_item.workflow_execution.user_id

                finally:
                    # Garante que a sess√£o seja fechada
                    try:
                        next(db_gen, None)  # Finaliza o generator
                    except StopIteration:
                        pass

                # Se encontrou uma execu√ß√£o para processar,
                # inicia com nova sess√£o
                if execution_id is not None and user_id is not None:
                    # Usa nova sess√£o para a execu√ß√£o
                    db_gen_exec = get_db()
                    db_exec = next(db_gen_exec)
                    try:
                        await self.start_execution(
                            db_exec, execution_id, user_id
                        )
                    finally:
                        try:
                            next(db_gen_exec, None)
                        except StopIteration:
                            pass

                await asyncio.sleep(1)  # Verifica a fila a cada segundo

            except (asyncio.CancelledError, DatabaseError) as e:
                logger.error("‚ùå Erro no processador de fila: %s", str(e))
                await asyncio.sleep(5)  # Espera mais tempo em caso de erro
            except Exception as e:
                logger.error(
                    "‚ùå Erro inesperado no processador de fila: %s", str(e)
                )
                await asyncio.sleep(5)  # Espera mais tempo em caso de erro

    async def _execute_workflow(
        self, db: Session, execution: WorkflowExecution
    ) -> None:
        """
        Executa um workflow completo
        """
        try:
            # Atualiza status para executando
            execution.status = ExecutionStatus.RUNNING  # type: ignore
            execution.started_at = datetime.utcnow()  # type: ignore
            db.commit()

            # Notifica in√≠cio
            if self.websocket_manager:
                await self.websocket_manager.send_to_user(
                    {
                        "type": "execution_started",
                        "execution_id": execution.execution_id,
                        "started_at": execution.started_at.isoformat(),
                    },
                    str(execution.user_id),  # type: ignore
                )

            # Carrega n√≥s para execu√ß√£o
            node_executions = (
                db.query(NodeExecution)
                .filter(NodeExecution.workflow_execution_id == execution.id)
                .order_by(NodeExecution.execution_order)
                .all()
            )

            # Executa n√≥s em ordem
            for node_execution in node_executions:
                if execution.status == ExecutionStatus.CANCELLED:
                    break

                # Verifica timeout
                if (
                    execution.timeout_at
                    and datetime.utcnow() > execution.timeout_at
                ):
                    execution.status = ExecutionStatus.TIMEOUT  # type: ignore
                    execution.error_message = (  # type: ignore
                        "Execu√ß√£o excedeu o tempo limite"
                    )
                    break

                # Executa o n√≥
                success = await self._execute_node(
                    db, execution, node_execution
                )

                if success:
                    execution.completed_nodes += 1  # type: ignore
                else:
                    execution.failed_nodes += 1  # type: ignore

                    # Se falhou e n√£o deve continuar, para a execu√ß√£o
                    if not node_execution.node.continue_on_error:
                        execution.status = (  # type: ignore
                            ExecutionStatus.FAILED
                        )
                        execution.error_message = (  # type: ignore
                            "N√≥ %s falhou e interrompeu a execu√ß√£o"
                            % node_execution.node_key
                        )
                        break

                # Atualiza progresso
                execution.update_progress()
                db.commit()

                # Notifica progresso
                if self.websocket_manager:
                    await self.websocket_manager.send_to_user(
                        {
                            "type": "execution_progress",
                            "execution_id": execution.execution_id,
                            "progress": execution.progress_percentage,
                            "completed_nodes": execution.completed_nodes,
                            "total_nodes": execution.total_nodes,
                        },
                        str(execution.user_id),  # type: ignore
                    )

            # Finaliza execu√ß√£o
            if execution.status == ExecutionStatus.RUNNING:
                execution.status = ExecutionStatus.COMPLETED  # type: ignore

            execution.completed_at = datetime.utcnow()  # type: ignore
            execution.actual_duration = (  # type: ignore
                execution.duration_seconds  # type: ignore
            )
            db.commit()

            # Remove da lista de execu√ß√µes ativas
            with self.execution_lock:
                if str(execution.execution_id) in self.running_executions:
                    del self.running_executions[str(execution.execution_id)]

            # Notifica conclus√£o
            if self.websocket_manager:
                await self.websocket_manager.send_to_user(
                    {
                        "type": "execution_completed",
                        "execution_id": execution.execution_id,
                        "status": execution.status.value,
                        "completed_at": execution.completed_at.isoformat(),
                        "duration_seconds": execution.actual_duration,
                    },
                    str(execution.user_id),  # type: ignore
                )

            logger.info(
                "‚úÖ Execu√ß√£o %s finalizada com status %s",
                execution.execution_id,
                execution.status.value,
            )

        except (asyncio.TimeoutError, DatabaseError) as e:
            logger.error(
                "‚ùå Erro na execu√ß√£o %s: %s", execution.execution_id, str(e)
            )

            # Marca como falha
            execution.status = ExecutionStatus.FAILED  # type: ignore
            execution.completed_at = datetime.utcnow()  # type: ignore
            execution.error_message = str(e)  # type: ignore
            execution.error_details = {  # type: ignore
                "traceback": traceback.format_exc()
            }
            db.commit()

            # Remove da lista de execu√ß√µes ativas
            with self.execution_lock:
                if str(execution.execution_id) in self.running_executions:
                    del self.running_executions[str(execution.execution_id)]

    async def _execute_node(
        self,
        db: Session,
        execution: WorkflowExecution,
        node_execution: NodeExecution,
    ) -> bool:
        """
        Executa um n√≥ espec√≠fico
        """
        try:
            # Atualiza status para executando
            node_execution.status = NodeExecutionStatus.RUNNING  # type: ignore
            node_execution.started_at = datetime.utcnow()  # type: ignore
            db.commit()

            start_time = time.time()

            # Simula execu√ß√£o do n√≥ (aqui voc√™ implementaria a l√≥gica real)
            # Por enquanto, vamos simular diferentes tipos de n√≥s
            await self._simulate_node_execution(node_execution)

            # Calcula dura√ß√£o
            duration_ms = int((time.time() - start_time) * 1000)

            # Marca como conclu√≠do
            node_execution.status = (  # type: ignore
                NodeExecutionStatus.COMPLETED  # type: ignore
            )
            node_execution.completed_at = datetime.utcnow()  # type: ignore
            node_execution.duration_ms = duration_ms  # type: ignore
            node_execution.output_data = {  # type: ignore
                "result": "success",
                "processed_at": datetime.utcnow().isoformat(),
            }

            db.commit()

            # Registra m√©trica
            await self._record_metric(
                db,
                int(execution.id),  # type: ignore
                int(node_execution.id),  # type: ignore
                "execution_time",
                "node_duration_ms",
                duration_ms,
            )

            return True

        except (asyncio.TimeoutError, ValueError) as e:
            logger.error(
                "‚ùå Erro na execu√ß√£o do n√≥ %s: %s",
                node_execution.node_key,
                str(e),
            )
            return False
        except Exception as e:
            logger.error(
                "‚ùå Erro inesperado na execu√ß√£o do n√≥ %s: %s",
                node_execution.node_key,
                str(e),
            )

            # Marca como falha
            node_execution.status = NodeExecutionStatus.FAILED  # type: ignore
            node_execution.completed_at = datetime.utcnow()  # type: ignore
            node_execution.error_message = str(e)  # type: ignore
            node_execution.error_details = {  # type: ignore
                "traceback": traceback.format_exc()
            }

            db.commit()
            return False

    async def _simulate_node_execution(
        self, node_execution: NodeExecution
    ) -> None:
        """
        Simula execu√ß√£o de diferentes tipos de n√≥s
        """
        node_type = node_execution.node_type.lower()

        if node_type == "api_call":
            # Simula chamada de API
            await asyncio.sleep(0.5)
        elif node_type == "data_processing":
            # Simula processamento de dados
            await asyncio.sleep(1.0)
        elif node_type == "ai_model":
            # Simula execu√ß√£o de modelo de IA
            await asyncio.sleep(2.0)
        elif node_type == "webhook":
            # Simula webhook
            await asyncio.sleep(0.3)
        else:
            # Execu√ß√£o padr√£o
            await asyncio.sleep(0.5)

    async def _validate_workflow(
        self, db: Session, workflow: Workflow, variables: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Valida um workflow antes da execu√ß√£o
        """
        errors = []
        warnings: List[str] = []

        # Carrega n√≥s do workflow
        nodes = db.query(Node).filter(Node.workflow_id == workflow.id).all()

        if not nodes:
            errors.append("Workflow n√£o possui n√≥s")

        # Valida vari√°veis necess√°rias
        required_vars = []
        for node in nodes:
            if node.config and isinstance(node.config, dict):
                # Extrai vari√°veis do config (formato ${VAR_NAME})
                config_str = json.dumps(node.config)
                vars_in_config = re.findall(r"\$\{([^}]+)\}", config_str)
                required_vars.extend(vars_in_config)

        # Remove duplicatas
        required_vars = list(set(required_vars))

        # Verifica se todas as vari√°veis necess√°rias est√£o dispon√≠veis
        missing_vars = [var for var in required_vars if var not in variables]
        if missing_vars:
            errors.append(
                "Vari√°veis necess√°rias n√£o encontradas: %s"
                % ", ".join(missing_vars)
            )

        # Estima dura√ß√£o (baseado no tipo e quantidade de n√≥s)
        estimated_duration = len(nodes) * 2  # 2 segundos por n√≥ em m√©dia

        return {
            "is_valid": len(errors) == 0,
            "errors": errors,
            "warnings": warnings,
            "total_nodes": len(nodes),
            "estimated_duration_seconds": estimated_duration,
            "required_variables": required_vars,
        }

    async def _create_node_executions(
        self, db: Session, execution: WorkflowExecution, workflow: Workflow
    ) -> None:
        """
        Cria execu√ß√µes para todos os n√≥s do workflow
        """
        nodes = (
            db.query(Node)
            .filter(Node.workflow_id == workflow.id)
            .order_by(Node.position)
            .all()
        )

        for i, node in enumerate(nodes):
            node_execution = NodeExecution(
                execution_id=str(uuid.uuid4()),
                workflow_execution_id=execution.id,
                node_id=node.id,
                node_key=node.key or f"node_{i}",
                node_type=node.type,
                node_name=node.name,
                execution_order=i,
                config_data=node.config,
                max_retries=3,
                retry_delay_ms=1000,
            )
            db.add(node_execution)

        db.commit()

    async def _add_to_queue(
        self, db: Session, execution: WorkflowExecution
    ) -> None:
        """
        Adiciona execu√ß√£o √† fila
        """
        queue_item = ExecutionQueue(
            queue_id=str(uuid.uuid4()),
            workflow_execution_id=execution.id,
            user_id=execution.user_id,
            priority=execution.priority,
            max_execution_time=3600,  # 1 hora por padr√£o
            max_retries=execution.max_retries,
        )
        db.add(queue_item)
        db.commit()

    async def _record_metric(
        self,
        db: Session,
        workflow_execution_id: int,
        node_execution_id: Optional[int],
        metric_type: str,
        metric_name: str,
        value: Union[int, float, str, Dict[str, Any]],
    ) -> None:
        """
        Registra uma m√©trica de execu√ß√£o
        """
        metric = ExecutionMetrics(
            workflow_execution_id=workflow_execution_id,
            node_execution_id=node_execution_id,
            metric_type=metric_type,
            metric_name=metric_name,
        )

        if isinstance(value, int):
            metric.value_numeric = value  # type: ignore
        elif isinstance(value, float):
            metric.value_float = str(value)  # type: ignore
        elif isinstance(value, str):
            metric.value_text = value  # type: ignore
        else:
            metric.value_json = value  # type: ignore

        db.add(metric)
        db.commit()


class ExecutionService:
    """
    Servi√ßo principal para gerenciamento de execu√ß√µes
    Interface de alto n√≠vel para a ExecutionEngine
    """

    def __init__(self, websocket_manager: Optional[ConnectionManager] = None):
        self.engine = ExecutionEngine(websocket_manager)

    async def start_engine(self) -> None:
        """Inicia a engine de execu√ß√£o"""
        await self.engine.start()

    async def stop_engine(self) -> None:
        """Para a engine de execu√ß√£o"""
        await self.engine.stop()

    async def create_and_start_execution(
        self,
        db: Session,
        execution_data: ExecutionCreate,
        user_id: int,
        start_immediately: bool = True,
    ) -> ExecutionResponse:
        """
        Cria e opcionalmente inicia uma execu√ß√£o
        """
        execution = await self.engine.create_execution(
            db, execution_data, user_id
        )

        if start_immediately:
            await self.engine.start_execution(
                db, execution.execution_id, user_id
            )

        return execution

    async def get_user_executions(
        self,
        db: Session,
        user_id: int,
        filters: Optional[ExecutionFilter] = None,
    ) -> List[ExecutionResponse]:
        """
        Obt√©m execu√ß√µes de um usu√°rio com filtros
        """
        query = db.query(WorkflowExecution).filter(
            WorkflowExecution.user_id == user_id
        )

        if filters:
            if filters.status:
                query = query.filter(
                    WorkflowExecution.status.in_(filters.status)
                )
            if filters.workflow_ids:
                query = query.filter(
                    WorkflowExecution.workflow_id.in_(filters.workflow_ids)
                )
            if filters.created_after:
                query = query.filter(
                    WorkflowExecution.created_at >= filters.created_after
                )
            if filters.created_before:
                query = query.filter(
                    WorkflowExecution.created_at <= filters.created_before
                )
            if filters.tags:
                # Filtro por tags (JSON contains)
                for tag in filters.tags:
                    query = query.filter(
                        WorkflowExecution.tags.contains([tag])
                    )

            # Ordena√ß√£o
            if filters.order_by == "created_at":
                order_col = WorkflowExecution.created_at
            elif filters.order_by == "updated_at":
                order_col = WorkflowExecution.updated_at
            elif filters.order_by == "started_at":
                order_col = WorkflowExecution.started_at
            elif filters.order_by == "completed_at":
                order_col = WorkflowExecution.completed_at
            elif filters.order_by == "priority":
                order_col = WorkflowExecution.priority  # type: ignore
            else:
                order_col = WorkflowExecution.created_at

            if filters.order_direction == "desc":
                query = query.order_by(desc(order_col))
            else:
                query = query.order_by(asc(order_col))

            # Pagina√ß√£o
            query = query.offset(filters.offset).limit(filters.limit)
        else:
            query = query.order_by(desc(WorkflowExecution.created_at)).limit(
                50
            )

        executions = query.all()
        return [ExecutionResponse.from_orm(e) for e in executions]

    async def get_execution_statistics(
        self, db: Session, user_id: int
    ) -> ExecutionStats:
        """
        Obt√©m estat√≠sticas de execu√ß√£o de um usu√°rio
        """
        # Contadores b√°sicos
        total = (
            db.query(WorkflowExecution)
            .filter(WorkflowExecution.user_id == user_id)
            .count()
        )
        running = (
            db.query(WorkflowExecution)
            .filter(
                WorkflowExecution.user_id == user_id,
                WorkflowExecution.status.in_(
                    [ExecutionStatus.PENDING, ExecutionStatus.RUNNING]
                ),
            )
            .count()
        )
        completed = (
            db.query(WorkflowExecution)
            .filter(
                WorkflowExecution.user_id == user_id,
                WorkflowExecution.status == ExecutionStatus.COMPLETED,
            )
            .count()
        )
        failed = (
            db.query(WorkflowExecution)
            .filter(
                WorkflowExecution.user_id == user_id,
                WorkflowExecution.status == ExecutionStatus.FAILED,
            )
            .count()
        )
        cancelled = (
            db.query(WorkflowExecution)
            .filter(
                WorkflowExecution.user_id == user_id,
                WorkflowExecution.status == ExecutionStatus.CANCELLED,
            )
            .count()
        )

        # Taxa de sucesso
        success_rate = (completed / total * 100) if total > 0 else 0

        # Dura√ß√£o m√©dia
        avg_duration = (
            db.query(func.avg(WorkflowExecution.actual_duration))
            .filter(
                WorkflowExecution.user_id == user_id,
                WorkflowExecution.actual_duration.isnot(None),
            )
            .scalar()
            or 0
        )

        # Total de n√≥s executados
        total_nodes = (
            db.query(func.sum(WorkflowExecution.completed_nodes))
            .filter(WorkflowExecution.user_id == user_id)
            .scalar()
            or 0
        )

        # M√©dia de n√≥s por execu√ß√£o
        avg_nodes = (total_nodes / total) if total > 0 else 0

        # Workflows mais usados - implementa√ß√£o simplificada
        most_used: List[Tuple[int, int]] = []
        try:
            most_used = (
                db.execute(
                    text("""
                        SELECT workflow_id, COUNT(*) as count
                        FROM workflow_executions
                        WHERE user_id = :user_id
                        GROUP BY workflow_id
                        ORDER BY count DESC
                        LIMIT 5
                    """),
                    {"user_id": user_id}
                ).fetchall()
            )
        except (DatabaseError, TypeError):
            # Em caso de erro, retorna lista vazia
            most_used = []

        return ExecutionStats(
            total_executions=total,
            running_executions=running,
            completed_executions=completed,
            failed_executions=failed,
            cancelled_executions=cancelled,
            average_duration_seconds=(
                float(avg_duration) if avg_duration else None
            ),
            success_rate_percentage=success_rate,
            total_nodes_executed=total_nodes,
            average_nodes_per_execution=avg_nodes,
            most_used_workflows=[
                {"workflow_id": w[0], "count": w[1]} for w in most_used
            ],
            execution_trends={},  # Implementar trends se necess√°rio
        )

    # M√©todos de conveni√™ncia que delegam para a engine
    async def cancel_execution(
        self,
        db: Session,
        execution_id: str,
        user_id: int,
        reason: Optional[str] = None,
    ) -> bool:
        return await self.engine.cancel_execution(
            db, execution_id, user_id, reason
        )

    async def retry_execution(
        self, db: Session, execution_id: str, user_id: int
    ) -> bool:
        return await self.engine.retry_execution(db, execution_id, user_id)

    async def get_execution_status(
        self, db: Session, execution_id: str, user_id: int
    ) -> Optional[ExecutionResponse]:
        return await self.engine.get_execution_status(
            db, execution_id, user_id
        )

    async def get_node_executions(
        self, db: Session, execution_id: str, user_id: int
    ) -> List[NodeExecutionResponse]:
        return await self.engine.get_node_executions(db, execution_id, user_id)

    async def get_execution_logs(
        self, db: Session, execution_id: str, user_id: int
    ) -> Dict[str, Any]:
        return await self.engine.get_execution_logs(db, execution_id, user_id)

    async def get_execution_metrics(
        self, db: Session, execution_id: str, user_id: int
    ) -> List[Dict[str, Any]]:
        return await self.engine.get_execution_metrics(
            db, execution_id, user_id
        )
