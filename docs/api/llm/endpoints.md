# Documenta√ß√£o da API de LLMs

## Vis√£o Geral

A API de LLMs do SynapScale permite integrar m√∫ltiplos provedores de modelos de linguagem atrav√©s de uma interface unificada. Esta abordagem oferece v√°rias vantagens:

- **Flexibilidade**: Escolha o provedor mais adequado para cada caso de uso
- **Resili√™ncia**: Fallback autom√°tico entre provedores em caso de falha
- **Extensibilidade**: Facilidade para adicionar novos provedores
- **Consist√™ncia**: Interface padronizada independente do provedor
- **üîë API Keys Personalizadas**: Usu√°rios podem configurar suas pr√≥prias API keys para cada provedor

## üîë Sistema de API Keys Espec√≠ficas por Usu√°rio

### Funcionalidade Principal

O sistema permite que cada usu√°rio configure suas pr√≥prias API keys para os provedores LLM, oferecendo:

- ‚úÖ **API Keys Personalizadas**: Cada usu√°rio pode usar suas pr√≥prias chaves
- ‚úÖ **Fallback Autom√°tico**: Se o usu√°rio n√£o tem API key configurada, usa a chave global do sistema
- ‚úÖ **Criptografia Segura**: Todas as API keys s√£o criptografadas com Fernet
- ‚úÖ **Transpar√™ncia Total**: Endpoints LLM funcionam normalmente, mas usam chaves espec√≠ficas automaticamente

### Provedores Suportados

- **OpenAI** (`openai`) - GPT-4, GPT-3.5-turbo, etc.
- **Anthropic** (`anthropic`) - Claude 3 Opus, Sonnet, Haiku
- **Google** (`google`) - Gemini 1.5 Pro, Gemini Pro
- **Grok** (`grok`) - Grok-1, Grok-2
- **DeepSeek** (`deepseek`) - DeepSeek Coder, Chat
- **Llama** (`llama`) - Llama 2, Code Llama

### Como Funciona

1. **Usu√°rio configura API key**: `POST /api/v1/user-variables/api-keys/openai`
2. **Sistema armazena criptografada**: Na tabela `user_variables` com `category="api_keys"`
3. **Uso autom√°tico**: Quando usu√°rio chama `/api/v1/llm/generate`, sistema usa sua API key automaticamente
4. **Fallback**: Se usu√°rio n√£o tem API key, usa a chave global do sistema

## Endpoints Dispon√≠veis

### Gera√ß√£o de Texto

```
POST /api/v1/llm/generate
```

Gera texto a partir de um prompt usando o provedor padr√£o ou especificado.

> üîë **API Keys Autom√°ticas**: Este endpoint usa automaticamente a API key espec√≠fica do usu√°rio se configurada, ou fallback para a chave global do sistema.

**Par√¢metros do Corpo**:
- `prompt` (string, obrigat√≥rio): Texto de entrada para o modelo
- `provider` (string, opcional): Provedor de LLM a ser usado
- `model` (string, opcional): Modelo espec√≠fico a ser usado
- `max_tokens` (integer, opcional): N√∫mero m√°ximo de tokens a gerar
- `temperature` (float, opcional): Temperatura para amostragem (0.0-1.0)
- `top_p` (float, opcional): Valor de top-p para amostragem nucleus
- `top_k` (integer, opcional): Valor de top-k para amostragem
- `use_cache` (boolean, opcional): Se deve usar o cache (se dispon√≠vel)

**Exemplo de Requisi√ß√£o**:
```json
{
  "prompt": "Explique o conceito de machine learning em termos simples.",
  "provider": "claude",
  "model": "claude-3-sonnet-20240229",
  "max_tokens": 500,
  "temperature": 0.7
}
```

**Exemplo de Resposta**:
```json
{
  "text": "Machine learning √© como ensinar um computador a aprender com exemplos, em vez de program√°-lo com regras espec√≠ficas...",
  "provider": "claude",
  "model": "claude-3-sonnet-20240229",
  "execution_time": 2.45,
  "cached": false
}
```

### Contagem de Tokens

```
POST /api/v1/llm/count-tokens
```

Conta o n√∫mero de tokens em um texto.

**Par√¢metros do Corpo**:
- `text` (string, obrigat√≥rio): Texto para contar tokens
- `provider` (string, opcional): Provedor de LLM a ser usado
- `model` (string, opcional): Modelo espec√≠fico a ser usado

**Exemplo de Requisi√ß√£o**:
```json
{
  "text": "Este √© um exemplo de texto para contar tokens.",
  "provider": "claude"
}
```

**Exemplo de Resposta**:
```json
{
  "token_count": 12,
  "provider": "claude",
  "model": "claude-3-sonnet-20240229"
}
```

### Listagem de Modelos

```
GET /api/v1/llm/models
```

Lista todos os modelos dispon√≠veis em todos os provedores configurados.

**Par√¢metros de Query**:
- `provider` (string, opcional): Filtrar por provedor espec√≠fico

**Exemplo de Resposta**:
```json
{
  "providers": {
    "claude": {
      "available": true,
      "models": [
        {
          "id": "claude-3-opus-20240229",
          "name": "Claude 3 Opus",
          "context_window": 200000,
          "capabilities": ["text-generation", "image-understanding", "reasoning"]
        },
        {
          "id": "claude-3-sonnet-20240229",
          "name": "Claude 3 Sonnet",
          "context_window": 200000,
          "capabilities": ["text-generation", "image-understanding"]
        }
      ]
    },
    "gemini": {
      "available": true,
      "models": [
        {
          "id": "gemini-1.5-pro-latest",
          "name": "Gemini 1.5 Pro",
          "context_window": 1000000,
          "capabilities": ["text-generation", "image-understanding", "code-generation"]
        }
      ]
    }
  }
}
```

### Listagem de Provedores

```
GET /api/v1/llm/providers
```

Lista todos os provedores dispon√≠veis e suas capacidades.

**Exemplo de Resposta**:
```json
{
  "providers": [
    {
      "name": "claude",
      "available": true,
      "capabilities": ["text-generation", "image-understanding"],
      "default_model": "claude-3-sonnet-20240229"
    },
    {
      "name": "gemini",
      "available": true,
      "capabilities": ["text-generation", "image-understanding", "code-generation"],
      "default_model": "gemini-1.5-pro-latest"
    }
  ],
  "default_provider": "claude"
}
```

### Endpoints Espec√≠ficos de Provedores

Al√©m dos endpoints gen√©ricos, cada provedor tem endpoints espec√≠ficos:

```
POST /api/v1/llm/{provider}/generate
POST /api/v1/llm/{provider}/count-tokens
GET /api/v1/llm/{provider}/models
```

Estes endpoints funcionam da mesma forma que os gen√©ricos, mas garantem o uso de um provedor espec√≠fico.

## C√≥digos de Erro

| C√≥digo | Descri√ß√£o | Solu√ß√£o |
|--------|-----------|---------|
| 401 | N√£o autorizado | Verifique o token de autentica√ß√£o |
| 403 | Acesso negado | Verifique as permiss√µes do usu√°rio |
| 404 | Recurso n√£o encontrado | Verifique o caminho da URL |
| 422 | Erro de valida√ß√£o | Verifique os par√¢metros da requisi√ß√£o |
| 500 | Erro interno do servidor | Verifique os logs do servidor |

## üîë Gerenciamento de API Keys de Usu√°rio

### Configurar API Key

```http
POST /api/v1/user-variables/api-keys/{provider}
Authorization: Bearer <access_token>
Content-Type: application/json

{
  "value": "sk-1234567890abcdef"
}
```

**Provedores suportados**: `openai`, `anthropic`, `google`, `grok`, `deepseek`, `llama`

### Listar API Keys

```http
GET /api/v1/user-variables/api-keys
Authorization: Bearer <access_token>
```

**Resposta** (valores mascarados para seguran√ßa):
```json
[
  {
    "id": "123e4567-e89b-12d3-a456-426614174000",
    "provider_name": "openai",
    "key_name": "OPENAI_API_KEY",
    "masked_value": "****cdef",
    "is_active": true,
    "description": "Chave da API OpenAI",
    "created_at": "2025-06-18T10:30:00Z",
    "updated_at": "2025-06-18T10:30:00Z"
  }
]
```

### Remover API Key

```http
DELETE /api/v1/user-variables/api-keys/{provider}
Authorization: Bearer <access_token>
```

### Listar Provedores Suportados

```http
GET /api/v1/user-variables/api-keys/providers
```

## Limita√ß√µes Conhecidas

- **Rate Limiting**: Todos os provedores imp√µem limites de requisi√ß√µes por minuto
- **Custo**: Chamadas √†s APIs externas geram custos baseados em tokens processados
- **Lat√™ncia**: Respostas podem levar v√°rios segundos, especialmente para prompts longos
- **Conte√∫do**: Alguns provedores filtram certos tipos de conte√∫do
- **Multimodalidade**: Nem todos os provedores suportam processamento de imagens
- **üîë API Keys**: Usu√°rios devem configurar suas pr√≥prias API keys para usar provedores espec√≠ficos (ou usar as chaves globais do sistema)
